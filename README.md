# ComfyUI-QwenVL-ALL

ComfyUI的Qwen-VL多模态模型集成插件，支持图像描述、视觉问答、视频分析等多种功能。

## 功能特点

### 🎯 核心节点功能
- **Qwen3-VL 图像描述生成器** - 基于Qwen3-VL模型生成高质量图像描述，支持自定义提示词
- **Qwen3-VL 视觉问答** - 基于图像的智能问答对话，支持多轮对话历史
- **Qwen3-VL 文本生成器** - 多模态文本生成和内容创作工具
- **Qwen3-VL 视频反推器** - 视频关键帧提取和智能描述生成

### ⚙️ 技术特性
- **多模型架构** - 支持Qwen3-VL-2B-Instruct（轻量快速）和Qwen3-VL-4B-Instruct（高质量）
- **智能设备管理** - 自动检测CUDA可用性，支持CPU/GPU无缝切换
- **高级量化系统** - 支持4位/8位量化，平衡性能与内存使用
- **注意力优化** - 标准注意力（兼容性好）和FlashAttention2（性能优先）
- **中文本地化** - 原生支持中文描述、问答和界面

### 🚀 用户体验
- **自动模型管理** - 首次使用自动下载，支持断点续传
- **批量处理能力** - 支持批量图像和视频处理
- **内存智能优化** - 动态内存管理，防止显存泄漏
- **错误友好提示** - 详细的错误信息和解决方案建议
- **参数智能预设** - 根据硬件配置自动推荐最优参数

## 核心节点

## 节点详细说明

### Qwen3-VL 图像描述生成器
**核心功能**
- 智能图像内容分析和详细描述生成
- 支持自定义提示词引导生成方向
- 批量图像处理能力

**技术参数**
- **模型选择**: Qwen3-VL-2B-Instruct（快速）/ Qwen3-VL-4B-Instruct（高质量）
- **输入支持**: 图像文件、自定义提示词（可选）
- **输出格式**: 详细描述文本、关键词列表
- **性能优化**: 支持量化、缓存机制、批量处理

### Qwen3-VL 视觉问答
**核心功能**
- 基于图像的智能问答对话系统
- 支持多轮对话历史记录
- 上下文理解和推理能力

**技术参数**
- **模型架构**: Qwen3-VL系列多模态模型
- **输入支持**: 图像、问题文本、历史对话（可选）
- **输出能力**: 准确回答、推理过程、相关建议
- **交互模式**: 单轮问答、多轮对话

### Qwen3-VL 文本生成器
**核心功能**
- 多模态文本生成和内容创作
- 支持图像引导的创意写作
- 多种生成模式和风格模板

**技术参数**
- **生成模式**: 创意写作、技术文档、营销文案等
- **输入支持**: 文本提示词、参考图像（可选）
- **风格控制**: 正式/随意、技术/通俗、创意/实用
- **输出质量**: 连贯性、相关性、创意性

### Qwen3-VL 视频反推器
**核心功能**
- 视频关键帧智能提取
- 视频内容深度分析和描述
- 多维度视频理解（场景、动作、情感）

**技术参数**
- **视频处理**: 关键帧提取、时序分析、内容理解
- **输入支持**: 视频文件、分析角度提示（可选）
- **输出能力**: 场景描述、动作分析、情感识别
- **效率优化**: 智能帧采样、并行处理

## 安装方法

### 方法一：通过ComfyUI Manager安装（推荐）
1. 打开ComfyUI Manager
2. 搜索 "Qwen-VL" 或 "ComfyUI-QwenVL-ALL"
3. 点击安装按钮
4. 重启ComfyUI完成安装

### 方法二：手动安装
1. 进入ComfyUI的 `custom_nodes` 目录
2. 克隆此仓库：
   ```bash
   git clone https://github.com/your-repo/ComfyUI-QwenVL-All.git
   ```
3. 安装依赖：
   ```bash
   cd ComfyUI-QwenVL-All
   pip install -r requirements.txt
   ```
4. 重启ComfyUI

### 依赖要求
- **Python**: 3.8或更高版本
- **PyTorch**: 2.0.0或更高版本（支持CUDA）
- **核心依赖**:
  - transformers>=4.40.0
  - accelerate>=0.20.0
  - qwen-vl-utils
  - Pillow>=9.0.0
- **可选依赖**:
  - flash-attn（启用FlashAttention2加速）
  - bitsandbytes（启用量化功能）

## 使用方法

1. 在节点浏览器中找到"Qwen-VL"类别
2. 选择需要的节点类型（图像描述、视觉问答、文本生成或视频反推）
3. 连接相应的输入（图像、视频或文本）
4. 配置模型参数：
   - **模型选择**：Qwen3-VL-2B-Instruct（轻量快速）或Qwen3-VL-4B-Instruct（高质量）
   - **设备选择**：自动、CUDA或CPU
   - **量化模式**：无量化（最高质量）、4位量化（平衡）、8位量化（节省内存）
   - **注意力类型**：标准注意力（兼容性好）、FlashAttention2（性能优先）
5. 运行工作流，模型将自动下载和加载
6. 获取生成的结果

## 节点说明

### Qwen3-VL 图像描述生成器
为图像生成详细的描述文本，适用于图像内容分析和理解。独立加载模型，自动下载和管理模型文件。

### Qwen3-VL 视觉问答
基于图像进行问答对话，支持多轮对话历史记录和上下文理解。

### Qwen3-VL 文本生成器
基于Qwen模型的智能文本生成和内容创作工具，支持多种生成模式和风格模板。

### Qwen3-VL 视频反推器
支持视频关键帧提取和智能描述生成，提供多种描述模式和分析角度。

**最新优化**：
- 精简模型选择，仅保留Qwen3-VL-2B/4B-Instruct核心模型
- 修复torch_dtype参数弃用警告，统一使用dtype参数
- 优化模型加载逻辑，支持缓存机制提升性能
- 增强错误处理和调试信息输出
- 完善中文本地化支持

## 注意事项

- **模型下载**：首次使用时会自动下载，约2-8GB，支持断点续传
- **性能建议**：推荐使用GPU，CPU模式速度较慢但可运行
- **内存优化**：量化选项可减少内存使用，4位量化平衡性能与质量
- **存储空间**：确保有足够磁盘空间存储模型文件
- **模型选择**：2B模型适合快速测试，4B模型适合高质量需求

## 故障排除

### 常见问题解决方案

**模型下载失败**
- ✅ 检查网络连接状态
- ✅ 确认磁盘空间充足（每个模型2-8GB）
- ✅ 手动下载：将模型文件放入 `ComfyUI/models/qwen3-vl/` 目录

**内存不足错误**
- ✅ 启用量化模式：优先尝试8位量化，再试4位量化
- ✅ 降低批量处理数量
- ✅ 检查GPU显存：建议至少6GB显存用于4B模型

**节点加载失败**
- ✅ 验证依赖安装：`pip install -r requirements.txt`
- ✅ 检查Python版本：需要Python 3.8或更高版本
- ✅ 查看ComfyUI控制台详细错误信息

**生成质量不佳**
- ✅ 调整生成参数：温度(0.1-1.0)、top_p值
- ✅ 检查输入质量：确保图像/视频清晰度
- ✅ 尝试不同模型：2B模型快速，4B模型质量高

**性能优化建议**
- ✅ GPU加速：确保CUDA可用且驱动更新
- ✅ 关闭其他GPU程序：释放显存资源
- ✅ 模型选择：根据硬件配置选择合适模型

## 更新日志

详见 [update.md](update.md) 文件获取完整版本历史